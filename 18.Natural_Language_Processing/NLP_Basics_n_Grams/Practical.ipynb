{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rvW_-ZJCAIZd"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdly1PCnE1ol",
        "outputId": "4caac0b5-a493-4f18-f733-f5a964172e6c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams(text, n):\n",
        "  tokens = word_tokenize(text)\n",
        "  n_grams = list(ngrams(tokens,n))\n",
        "  return n_grams"
      ],
      "metadata": {
        "id": "sGrPyzpgE39k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text\n",
        "txt = \"N-Grams are a sequence of n items from a given sample of text or speech\"\n",
        "\n",
        "unigrams = generate_ngrams(txt,1)\n",
        "bigrams = generate_ngrams(txt,2)\n",
        "trigrams = generate_ngrams(txt,3)"
      ],
      "metadata": {
        "id": "x9G8JPVcFCCU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3BmQEN_FRH8",
        "outputId": "c09d47f2-8299-466c-eae1-7b9145a4ac3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('N-Grams',), ('are',), ('a',), ('sequence',), ('of',), ('n',), ('items',), ('from',), ('a',), ('given',), ('sample',), ('of',), ('text',), ('or',), ('speech',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6ZeeM3_FSkM",
        "outputId": "0365b4c3-7c9d-4824-c3a9-67f0d62b0230"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('N-Grams', 'are'), ('are', 'a'), ('a', 'sequence'), ('sequence', 'of'), ('of', 'n'), ('n', 'items'), ('items', 'from'), ('from', 'a'), ('a', 'given'), ('given', 'sample'), ('sample', 'of'), ('of', 'text'), ('text', 'or'), ('or', 'speech')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsQvSy-6FVC8",
        "outputId": "a34bc9de-94a1-4386-b1ae-4facc08c06fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('N-Grams', 'are', 'a'), ('are', 'a', 'sequence'), ('a', 'sequence', 'of'), ('sequence', 'of', 'n'), ('of', 'n', 'items'), ('n', 'items', 'from'), ('items', 'from', 'a'), ('from', 'a', 'given'), ('a', 'given', 'sample'), ('given', 'sample', 'of'), ('sample', 'of', 'text'), ('of', 'text', 'or'), ('text', 'or', 'speech')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dk2hDXK7FYkc"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}